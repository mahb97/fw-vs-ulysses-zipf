{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTRunVLtSkx3XOtdCSLZ9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/fw-vs-ulysses-zipf/blob/main/fit_zipf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSoKWpPQar-K",
        "outputId": "7d4e5340-2800-4845-e998-63e900583289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ROOT: /content/drive/MyDrive/zipf_joyce\n",
            "Processed: /content/drive/MyDrive/zipf_joyce/data/processed\n",
            "Tables: /content/drive/MyDrive/zipf_joyce/results/tables\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "import regex as re\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, List\n",
        "import math, json, warnings\n",
        "\n",
        "# Colab / Drive\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive, files\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    ROOT = Path(\"/content/drive/MyDrive/zipf_joyce\").resolve()\n",
        "else:\n",
        "    ROOT = (Path.cwd() / \"zipf_joyce_local\").resolve()\n",
        "\n",
        "DATA_PROC = ROOT / \"data\" / \"processed\"\n",
        "RESULTS   = ROOT / \"results\"\n",
        "TABLES    = RESULTS / \"tables\"\n",
        "FIGS      = RESULTS / \"figures\"\n",
        "for p in (TABLES, FIGS): p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"ROOT:\", ROOT)\n",
        "print(\"Processed:\", DATA_PROC)\n",
        "print(\"Tables:\", TABLES)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re, unicodedata as ud\n",
        "\n",
        "# Redefine CONFIGS with an explicit flag instead of relying on object identity\n",
        "CONFIGS = {\n",
        "    \"conservative\": dict(lower=False, nfkc=True, split_hyphens=False, remove_digits=False, min_len=1, fw_split_camel=False),\n",
        "    \"canonical\":    dict(lower=True,  nfkc=True, split_hyphens=True,  remove_digits=True,  min_len=1, fw_split_camel=False),\n",
        "    \"generous\":     dict(lower=True,  nfkc=True, split_hyphens=True,  remove_digits=True,  min_len=1, fw_split_camel=True),\n",
        "}\n",
        "\n",
        "# Rebind tokenize()\n",
        "WORD_RE = re.compile(r\"\\p{L}[\\p{L}\\p{M}\\p{Pd}\\p{Pc}\\']*\")\n",
        "\n",
        "def tokenize(text: str, cfg: dict):\n",
        "    s = text\n",
        "    if cfg.get(\"nfkc\", True):\n",
        "        s = ud.normalize(\"NFKC\", s)\n",
        "    if cfg.get(\"lower\", True):\n",
        "        s = s.lower()\n",
        "    if cfg.get(\"remove_digits\", False):\n",
        "        s = re.sub(r\"\\p{N}+\", \" \", s)\n",
        "    toks = WORD_RE.findall(s)\n",
        "    if cfg.get(\"split_hyphens\", False):\n",
        "        split = []\n",
        "        for t in toks:\n",
        "            split.extend(t.split(\"-\"))\n",
        "        toks = [t for t in split if t]\n",
        "    if cfg.get(\"fw_split_camel\", False):\n",
        "        # Split lower→Upper seams\n",
        "        g = []\n",
        "        for t in toks:\n",
        "            g.extend(re.sub(r\"(?<=[\\p{Ll}])(?=[\\p{Lu}])\", \" \", t).split())\n",
        "        toks = g\n",
        "    mlen = cfg.get(\"min_len\", 1)\n",
        "    return [t for t in toks if len(t) >= mlen]"
      ],
      "metadata": {
        "id": "4dweC5teyge6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Three tokenisation tracks\n",
        "CONFIGS = {\n",
        "    \"conservative\": dict(lower=False, nfkc=True, split_hyphens=False, remove_digits=False, min_len=1),\n",
        "    \"canonical\":    dict(lower=True,  nfkc=True, split_hyphens=True,  remove_digits=True,  min_len=1),\n",
        "    \"generous\":     dict(lower=True,  nfkc=True, split_hyphens=True,  remove_digits=True,  min_len=1), # FW-aware extras below\n",
        "}\n",
        "\n",
        "WORD_RE = re.compile(r\"\\p{L}[\\p{L}\\p{M}\\p{Pd}\\p{Pc}\\']*\")\n",
        "\n",
        "def tokenize(text: str, cfg: Dict) -> List[str]:\n",
        "    s = text\n",
        "    if cfg.get(\"nfkc\", True):\n",
        "        import unicodedata as ud\n",
        "        s = ud.normalize(\"NFKC\", s)\n",
        "    if cfg.get(\"lower\", True):\n",
        "        s = s.lower()\n",
        "    if cfg.get(\"remove_digits\", False):\n",
        "        s = re.sub(r\"\\p{N}+\", \" \", s)\n",
        "    toks = WORD_RE.findall(s)\n",
        "    if cfg.get(\"split_hyphens\", False):\n",
        "        spl = []\n",
        "        for t in toks:\n",
        "            spl.extend(t.split(\"-\"))\n",
        "        toks = [t for t in spl if t]\n",
        "    # FW-aware split (very light touch)\n",
        "    if cfg is CONFIGS[\"generous\"]:\n",
        "        g = []\n",
        "        for t in toks:\n",
        "            g.extend(re.sub(r\"(?<=[\\p{Ll}])(?=[\\p{Lu}])\", \" \", t).split())\n",
        "        toks = g\n",
        "    mlen = cfg.get(\"min_len\", 1)\n",
        "    toks = [t for t in toks if len(t) >= mlen]\n",
        "    return toks\n",
        "\n",
        "def load_processed(name: str) -> str:\n",
        "    p = DATA_PROC / f\"{name}.txt\"\n",
        "    return p.read_text(encoding=\"utf-8\")\n",
        "\n",
        "TEXTS = {\"FW\": load_processed(\"fw\"), \"Ulysses\": load_processed(\"ulysses\")}\n",
        "print(\"Loaded texts:\", {k: f\"{len(v):,} chars\" for k,v in TEXTS.items()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE8X7DWsa4Nd",
        "outputId": "8fd73401-1fc7-4d28-9526-e65a87ce3589"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded texts: {'FW': '1,304,732 chars', 'Ulysses': '1,516,830 chars'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, text in TEXTS.items():\n",
        "    toks_can = tokenize(text, CONFIGS[\"canonical\"])\n",
        "    toks_gen = tokenize(text, CONFIGS[\"generous\"])\n",
        "    print(f\"{name}: canonical types={len(set(toks_can)):,}  generous types={len(set(toks_gen)):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlYbhjd02Ooe",
        "outputId": "089fe113-3304-4f95-e061-ae210aebe11e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FW: canonical types=58,083  generous types=58,083\n",
            "Ulysses: canonical types=29,375  generous types=29,375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zipf: discrete MLE, KS, bootstrap, alternatives**"
      ],
      "metadata": {
        "id": "lk56OknTbH8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make \"generous\" vs \"canonical\"\n",
        "import regex as re, unicodedata as ud\n",
        "\n",
        "CONFIGS = {\n",
        "    \"conservative\": dict(lower=False, nfkc=True, split_hyphens=False, remove_digits=False, min_len=1,\n",
        "                         fw_split_camel=False, generous_punct=False),\n",
        "    \"canonical\":    dict(lower=True,  nfkc=True, split_hyphens=True,  remove_digits=True,  min_len=1,\n",
        "                         fw_split_camel=False, generous_punct=False),\n",
        "    \"generous\":     dict(lower=True,  nfkc=True, split_hyphens=True,  remove_digits=True,  min_len=1,\n",
        "                         fw_split_camel=True,  generous_punct=True),\n",
        "}\n",
        "\n",
        "WORD_RE = re.compile(r\"\\p{L}[\\p{L}\\p{M}\\p{Pd}\\p{Pc}’']*\")\n",
        "\n",
        "GENEROUS_SPLIT_CHARS = \"[/·\\u00B7\\u2012-\\u2015\\u2212]\"\n",
        "\n",
        "def tokenize(text: str, cfg: dict):\n",
        "    s = text\n",
        "\n",
        "    if cfg.get(\"nfkc\", True):\n",
        "        s = ud.normalize(\"NFKC\", s)\n",
        "\n",
        "    # (generous) split on punctuation joiners\n",
        "    if cfg.get(\"generous_punct\", False):\n",
        "        s = re.sub(GENEROUS_SPLIT_CHARS, \" \", s)\n",
        "\n",
        "    # (generous) split camelCase\n",
        "    if cfg.get(\"fw_split_camel\", False):\n",
        "        s = re.sub(r\"(?<=[\\p{Ll}])(?=[\\p{Lu}])\", \" \", s)\n",
        "\n",
        "    if cfg.get(\"lower\", True):\n",
        "        s = s.lower()\n",
        "    if cfg.get(\"remove_digits\", False):\n",
        "        s = re.sub(r\"\\p{N}+\", \" \", s)\n",
        "\n",
        "    # Extract word tokens\n",
        "    toks = WORD_RE.findall(s)\n",
        "\n",
        "    # Opt split on hyphens\n",
        "    if cfg.get(\"split_hyphens\", False):\n",
        "        tt = []\n",
        "        for t in toks:\n",
        "            tt.extend(t.split(\"-\"))\n",
        "        toks = [t for t in tt if t]\n",
        "\n",
        "    # Length filter\n",
        "    mlen = cfg.get(\"min_len\", 1)\n",
        "    return [t for t in toks if len(t) >= mlen]\n"
      ],
      "metadata": {
        "id": "JQ0nJndm34_0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, text in TEXTS.items():\n",
        "    toks_can = tokenize(text, CONFIGS[\"canonical\"])\n",
        "    toks_gen = tokenize(text, CONFIGS[\"generous\"])\n",
        "    print(f\"{name}: canonical types={len(set(toks_can)):,}  generous types={len(set(toks_gen)):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jP2Ate43-io",
        "outputId": "eab25973-da62-403d-e537-23a0d3e0e064"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FW: canonical types=58,083  generous types=58,019\n",
            "Ulysses: canonical types=30,187  generous types=30,158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core: discrete power-law, Hurwitz zeta via mpmath\n",
        "import mpmath as mp\n",
        "from scipy.optimize import minimize_scalar, minimize\n",
        "from numpy.random import default_rng\n",
        "from scipy.stats import norm\n",
        "\n",
        "mp.mp.dps = 50  # high precision for zeta\n",
        "\n",
        "def hurwitz_zeta(alpha: float, xmin: int) -> float:\n",
        "    return float(mp.zeta(alpha, xmin))\n",
        "\n",
        "def loglik_discrete_powerlaw(xs: np.ndarray, alpha: float, xmin: int) -> float:\n",
        "    if alpha <= 1: return -np.inf\n",
        "    Z = hurwitz_zeta(alpha, xmin)\n",
        "    if not np.isfinite(Z) or Z <= 0: return -np.inf\n",
        "    return - xs.size * math.log(Z) - alpha * np.log(xs).sum()\n",
        "\n",
        "def mle_alpha_discrete(xs: np.ndarray, xmin: int) -> float:\n",
        "    def nll(a): return -loglik_discrete_powerlaw(xs, a, xmin)\n",
        "    res = minimize_scalar(nll, bounds=(1.0001, 5.0), method=\"bounded\")\n",
        "    return float(res.x)\n",
        "\n",
        "def cdf_discrete_powerlaw_support(alpha: float, xmin: int, xmax: int) -> np.ndarray:\n",
        "    # returns CDF over support [xmin..xmax]\n",
        "    ks = np.arange(xmin, xmax+1, dtype=int)\n",
        "    w = ks.astype(float)**(-alpha)\n",
        "    W = w.cumsum()\n",
        "    return W / W[-1]\n",
        "\n",
        "def ks_statistic(xs: np.ndarray, alpha: float, xmin: int) -> float:\n",
        "    # xs: tail sample (>= xmin)\n",
        "    xs = np.sort(xs)\n",
        "    uniq, counts = np.unique(xs, return_counts=True)\n",
        "    ecdf = np.cumsum(counts) / xs.size\n",
        "    F = cdf_discrete_powerlaw_support(alpha, xmin, uniq.max())\n",
        "    # align CDF values to uniq indices\n",
        "    # F[k - xmin] is CDF at k\n",
        "    model = F[uniq - xmin]\n",
        "    return float(np.max(np.abs(ecdf - model)))\n",
        "\n",
        "def choose_xmin_by_ks(counts: np.ndarray, xmin_candidates: List[int]) -> Tuple[int, float, float]:\n",
        "    \"\"\"Return (xmin, alpha, ksD) minimizing KS distance.\"\"\"\n",
        "    best = (None, None, np.inf)\n",
        "    for xm in xmin_candidates:\n",
        "        tail = counts[counts >= xm]\n",
        "        if tail.size < 50:  # safety\n",
        "            continue\n",
        "        a = mle_alpha_discrete(tail, xm)\n",
        "        D = ks_statistic(tail, a, xm)\n",
        "        if D < best[2]:\n",
        "            best = (xm, a, D)\n",
        "    if best[0] is None:\n",
        "        raise ValueError(\"No valid xmin candidate produced sufficient tail.\")\n",
        "    return best  # xmin, alpha, D\n",
        "\n",
        "def parametric_ks_bootstrap(counts: np.ndarray, alpha: float, xmin: int, B: int = 800, seed: int = 42) -> float:\n",
        "    \"\"\"KS p-value via parametric bootstrap: synthetic samples from fitted model (tail size preserved).\"\"\"\n",
        "    rng = default_rng(seed)\n",
        "    tail = counts[counts >= xmin]\n",
        "    n = tail.size\n",
        "    # Build tail pmf over [xmin..K] with mass cutoff\n",
        "    K = max(int(tail.max()*3), xmin+1000)\n",
        "    ks = np.arange(xmin, K+1)\n",
        "    w = ks.astype(float)**(-alpha)\n",
        "    pmf = w / w.sum()\n",
        "    D_obs = ks_statistic(tail, alpha, xmin)\n",
        "    ge = 0\n",
        "    for _ in range(B):\n",
        "        sim = rng.choice(ks, size=n, replace=True, p=pmf)\n",
        "        a_sim = mle_alpha_discrete(sim, xmin)\n",
        "        D_sim = ks_statistic(sim, a_sim, xmin)\n",
        "        if D_sim >= D_obs:\n",
        "            ge += 1\n",
        "    return (ge + 1) / (B + 1)\n",
        "\n",
        "def bootstrap_alpha_ci(counts: np.ndarray, xmin: int, B: int = 800, seed: int = 7) -> Tuple[float, float]:\n",
        "    rng = default_rng(seed)\n",
        "    tail = counts[counts >= xmin]\n",
        "    n = tail.size\n",
        "    alphas = np.empty(B, float)\n",
        "    for b in range(B):\n",
        "        samp = rng.choice(tail, size=n, replace=True)\n",
        "        alphas[b] = mle_alpha_discrete(samp, xmin)\n",
        "    return float(np.percentile(alphas, 2.5)), float(np.percentile(alphas, 97.5))"
      ],
      "metadata": {
        "id": "3nPkY7JhbDFO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternative models + ML estimates (for LR tests)**"
      ],
      "metadata": {
        "id": "XcVb1p99bgw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lognormal (discretised), truncated power law, Zipf–Mandelbrot\n",
        "def fit_lognormal_tail(xs: np.ndarray, xmin: int) -> Tuple[float, float]:\n",
        "    x = np.log(xs)\n",
        "    mu = float(x.mean()); sigma = float(x.std(ddof=1))\n",
        "    return mu, max(sigma, 1e-6)\n",
        "\n",
        "def fit_truncated_pl_tail(xs: np.ndarray, xmin: int) -> Tuple[float, float]:\n",
        "    xs = xs.astype(float)\n",
        "    def nll(params):\n",
        "        alpha, lam = params\n",
        "        if alpha <= 0 or lam <= 0: return 1e12\n",
        "        # normalisation over support\n",
        "        K = max(int(xs.max()*3), xmin+1000)\n",
        "        ks = np.arange(xmin, K+1, dtype=float)\n",
        "        Z = np.sum(ks**(-alpha) * np.exp(-lam*ks))\n",
        "        if not np.isfinite(Z) or Z <= 0: return 1e12\n",
        "        ll = -np.sum(alpha*np.log(xs) + lam*xs + np.log(Z))\n",
        "        return -ll\n",
        "    res = minimize(nll, x0=np.array([1.5, 1e-3]), bounds=[(1e-6, 5.0), (1e-9, 1.0)])\n",
        "    return float(res.x[0]), float(res.x[1])\n",
        "\n",
        "def fit_zipf_mandelbrot_tail(xs: np.ndarray, xmin: int) -> Tuple[float, float]:\n",
        "    # p(k) ∝ (k+q)^(-s) with s>0, q≥0\n",
        "    def nll(params):\n",
        "        s, q = params\n",
        "        if s <= 0 or q < 0: return 1e12\n",
        "        K = max(int(xs.max()*3), xmin+1000)\n",
        "        ks = np.arange(xmin, K+1, dtype=float)\n",
        "        Z = np.sum((ks + q)**(-s))\n",
        "        if not np.isfinite(Z) or Z <= 0: return 1e12\n",
        "        ll = -np.sum(s*np.log(xs + q) + np.log(Z))\n",
        "        return -ll\n",
        "    res = minimize(nll, x0=np.array([1.2, 1.0]), bounds=[(1e-6, 10.0), (0.0, 100.0)])\n",
        "    return float(res.x[0]), float(res.x[1])\n",
        "\n",
        "def lr_test_same_support(xs: np.ndarray, xmin: int, logpmfA, logpmfB) -> Tuple[float, float, float]:\n",
        "    \"\"\"Return (LR, z, p) for Vuong. xs are tail counts >= xmin.\"\"\"\n",
        "    xs = xs[xs >= xmin]\n",
        "    lA = logpmfA(xs); lB = logpmfB(xs)\n",
        "    diff = lA - lB\n",
        "    LR = float(diff.sum())\n",
        "    sd = float(np.std(diff, ddof=1))\n",
        "    z = LR / (sd * math.sqrt(len(diff)) + 1e-12)\n",
        "    p = 2*(1 - norm.cdf(abs(z)))\n",
        "    return LR, z, p\n",
        "\n",
        "def make_logpmfs_for_tail(xmin: int, params: Dict[str, float], model: str):\n",
        "    # returns a vectorised logpmf(x_array)\n",
        "    if model == \"powerlaw\":\n",
        "        alpha = params[\"alpha\"]\n",
        "        K = None  # use Hurwitz zeta exact normaliser\n",
        "        def logpmf(x):\n",
        "            Z = hurwitz_zeta(alpha, xmin)\n",
        "            return -alpha*np.log(x) - np.log(Z)\n",
        "        return np.vectorize(logpmf)\n",
        "    if model == \"lognormal\":\n",
        "        mu, sigma = params[\"mu\"], params[\"sigma\"]\n",
        "        K = None\n",
        "        def logpmf(x):\n",
        "            # discretised via PDF approx, renormed\n",
        "            x = x.astype(float)\n",
        "            pdf = (1/(x*sigma*math.sqrt(2*math.pi)))*np.exp(-(np.log(x)-mu)**2/(2*sigma**2))\n",
        "            # renormalise on tail\n",
        "            Kmax = int(max(x.max()*3, xmin+1000))\n",
        "            ks = np.arange(xmin, Kmax+1, dtype=float)\n",
        "            denom = (1/(ks*sigma*math.sqrt(2*math.pi)))*np.exp(-(np.log(ks)-mu)**2/(2*sigma**2))\n",
        "            denom = denom.sum()\n",
        "            return np.log(pdf) - np.log(denom + 1e-300)\n",
        "        return logpmf\n",
        "    if model == \"truncated\":\n",
        "        alpha, lam = params[\"alpha\"], params[\"lam\"]\n",
        "        def logpmf(x):\n",
        "            Kmax = int(max(x.max()*3, xmin+1000))\n",
        "            ks = np.arange(xmin, Kmax+1, dtype=float)\n",
        "            denom = np.sum((ks**(-alpha))*np.exp(-lam*ks))\n",
        "            return -alpha*np.log(x) - lam*x - np.log(denom + 1e-300)\n",
        "        return logpmf\n",
        "    if model == \"zipf_mandelbrot\":\n",
        "        s, q = params[\"s\"], params[\"q\"]\n",
        "        def logpmf(x):\n",
        "            Kmax = int(max(x.max()*3, xmin+1000))\n",
        "            ks = np.arange(xmin, Kmax+1, dtype=float)\n",
        "            denom = np.sum((ks + q)**(-s))\n",
        "            return -s*np.log(x + q) - np.log(denom + 1e-300)\n",
        "        return logpmf\n",
        "    raise ValueError(\"Unknown model\")"
      ],
      "metadata": {
        "id": "O9_BTra3bdv5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit wrapper (per text × pipeline) + exports**"
      ],
      "metadata": {
        "id": "hFDhwtthdIpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def counts_from_tokens(tokens: List[str]) -> np.ndarray:\n",
        "    return np.array(list(Counter(tokens).values()), dtype=int)\n",
        "\n",
        "def xmin_candidates_for(counts: np.ndarray, xmin_min: int = 2, max_unique: int = 500) -> np.ndarray:\n",
        "    u = np.unique(counts)\n",
        "    u = u[u >= xmin_min]\n",
        "    return u[:max_unique]\n",
        "\n",
        "def fit_all_models(counts: np.ndarray, xmin: int, alpha_hat: float) -> pd.DataFrame:\n",
        "    tail = counts[counts >= xmin]\n",
        "    rows = []\n",
        "    # powerlaw\n",
        "    rows.append(dict(model=\"powerlaw\", alpha=alpha_hat))\n",
        "    # lognormal\n",
        "    mu, sigma = fit_lognormal_tail(tail, xmin)\n",
        "    rows.append(dict(model=\"lognormal\", mu=mu, sigma=sigma))\n",
        "    # truncated\n",
        "    a_t, lam = fit_truncated_pl_tail(tail, xmin)\n",
        "    rows.append(dict(model=\"truncated\", alpha=a_t, lam=lam))\n",
        "    # zipf-mandelbrot\n",
        "    s, q = fit_zipf_mandelbrot_tail(tail, xmin)\n",
        "    rows.append(dict(model=\"zipf_mandelbrot\", s=s, q=q))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def compare_models_lr(counts: np.ndarray, xmin: int, param_table: pd.DataFrame) -> pd.DataFrame:\n",
        "    tail = counts[counts >= xmin]\n",
        "    # build logpmfs\n",
        "    lp = {}\n",
        "    for _, row in param_table.iterrows():\n",
        "        model = row[\"model\"]\n",
        "        params = {k: row[k] for k in row.index if k not in [\"model\"] and not pd.isna(row[k])}\n",
        "        lp[model] = make_logpmfs_for_tail(xmin, params, model)\n",
        "    # pairwise vs powerlaw\n",
        "    out = []\n",
        "    for other in [\"lognormal\", \"truncated\", \"zipf_mandelbrot\"]:\n",
        "        LR, z, p = lr_test_same_support(tail, xmin, lp[\"powerlaw\"], lp[other])\n",
        "        out.append(dict(comp=f\"powerlaw_vs_{other}\", LR=LR, z=z, p=p))\n",
        "    return pd.DataFrame(out)\n",
        "\n",
        "def heaps_curve(tokens: List[str], steps: int = 200) -> pd.DataFrame:\n",
        "    N = len(tokens)\n",
        "    step = max(1000, N // steps)\n",
        "    vocab = set()\n",
        "    Ns, Vs = [], []\n",
        "    for i in range(step, N+1, step):\n",
        "        for t in tokens[i-step:i]:\n",
        "            vocab.add(t)\n",
        "        Ns.append(i); Vs.append(len(vocab))\n",
        "    df = pd.DataFrame(dict(N=Ns, V=Vs))\n",
        "    # Estimate beta by OLS on log-log (descriptive)\n",
        "    x = np.log(df[\"N\"].values)\n",
        "    y = np.log(df[\"V\"].values + 1e-9)\n",
        "    beta, logK = np.polyfit(x, y, 1)\n",
        "    df.attrs[\"beta_hat\"] = float(beta)\n",
        "    df.attrs[\"K_hat\"] = float(np.exp(logK))\n",
        "    return df\n",
        "\n",
        "def bootstrap_heaps_beta(tokens: List[str], B: int = 400, steps: int = 200, seed: int = 11) -> Tuple[float,float]:\n",
        "    rng = default_rng(seed)\n",
        "    Ns = len(tokens)\n",
        "    betas = np.empty(B, float)\n",
        "    for b in range(B):\n",
        "        # block bootstrap: resample contiguous blocks (approximate dependence)\n",
        "        block = max(1000, Ns // steps)\n",
        "        idx = []\n",
        "        while len(idx) < Ns:\n",
        "            start = int(rng.integers(0, max(1, Ns - block)))\n",
        "            idx.extend(range(start, min(Ns, start + block)))\n",
        "        idx = idx[:Ns]\n",
        "        sample = [tokens[i] for i in idx]\n",
        "        hc = heaps_curve(sample, steps=steps)\n",
        "        betas[b] = hc.attrs[\"beta_hat\"]\n",
        "    return float(np.percentile(betas, 2.5)), float(np.percentile(betas, 97.5))\n",
        "\n",
        "def windowed_s(tokens: List[str], window: int = 25000, step: int = 5000, xmin_min: int = 2) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for start in range(0, max(1, len(tokens) - window + 1), step):\n",
        "        seg = tokens[start:start+window]\n",
        "        counts = counts_from_tokens(seg)\n",
        "        xmins = xmin_candidates_for(counts, xmin_min=xmin_min, max_unique=300)\n",
        "        try:\n",
        "            xmin, alpha, D = choose_xmin_by_ks(counts, xmins.tolist())\n",
        "        except Exception:\n",
        "            continue\n",
        "        n_tail = int((counts >= xmin).sum())\n",
        "        rows.append(dict(window_start=start, window_end=start+window, xmin=xmin, s_hat=alpha, ks_D=D, n_tail=n_tail))\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "YGkNk57hdLOD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fits for each pipeline; export CSVs**"
      ],
      "metadata": {
        "id": "cjnSHP3IdfX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_FITS = []\n",
        "ALL_LR   = []\n",
        "ALL_HEAPS = []\n",
        "ALL_RANKF = []\n",
        "ALL_WINS = []\n",
        "\n",
        "for pipe, cfg in CONFIGS.items():\n",
        "    print(f\"\\n=== PIPELINE: {pipe} ===\")\n",
        "    for text_name, text in TEXTS.items():\n",
        "        print(f\"\\n→ Tokenising {text_name} …\")\n",
        "        tokens = tokenize(text, cfg)\n",
        "        counts = counts_from_tokens(tokens)\n",
        "        print(f\"{text_name}: tokens={len(tokens):,}  types={len(counts):,}\")\n",
        "        # xmin selection + alpha\n",
        "        xmins = xmin_candidates_for(counts, xmin_min=2, max_unique=500)\n",
        "        xmin, alpha, D = choose_xmin_by_ks(counts, xmins.tolist())\n",
        "        n_tail = int((counts >= xmin).sum())\n",
        "        print(f\"{text_name}: xmin={xmin}  alpha={alpha:.4f}  KS D={D:.4f}  tail_n={n_tail:,}\")\n",
        "        # KS bootstrap + alpha CI\n",
        "        ks_p = parametric_ks_bootstrap(counts, alpha, xmin, B=800, seed=42)\n",
        "        ci_lo, ci_hi = bootstrap_alpha_ci(counts, xmin, B=800, seed=7)\n",
        "        # store headline row\n",
        "        ALL_FITS.append(dict(text=text_name, pipeline=pipe, model=\"powerlaw\",\n",
        "                             s=alpha, s_ci_low=ci_lo, s_ci_high=ci_hi,\n",
        "                             x_min=xmin, ks_D=D, ks_p=ks_p,\n",
        "                             tokens=len(tokens), types=len(counts), n_tail=n_tail))\n",
        "        # Alternatives + LR\n",
        "        params = fit_all_models(counts, xmin, alpha)\n",
        "        lr = compare_models_lr(counts, xmin, params)\n",
        "        lr[\"text\"] = text_name; lr[\"pipeline\"] = pipe; lr[\"xmin\"] = xmin\n",
        "        ALL_LR.append(lr)\n",
        "        # Heaps\n",
        "        hc = heaps_curve(tokens, steps=240)\n",
        "        beta = hc.attrs[\"beta_hat\"]; Khat = hc.attrs[\"K_hat\"]\n",
        "        beta_lo, beta_hi = bootstrap_heaps_beta(tokens, B=300, steps=180, seed=13)\n",
        "        ALL_HEAPS.append(pd.DataFrame({\n",
        "            \"text\":[text_name], \"pipeline\":[pipe], \"beta_hat\":[beta],\n",
        "            \"beta_ci_low\":[beta_lo], \"beta_ci_high\":[beta_hi],\n",
        "            \"K_hat\":[Khat]\n",
        "        }))\n",
        "        # rank-frequency (for dashboard)\n",
        "        freqs = np.array(sorted(counts, reverse=True))\n",
        "        rf = pd.DataFrame({\"text\":text_name, \"pipeline\":pipe,\n",
        "                           \"rank\":np.arange(1, freqs.size+1), \"freq\":freqs})\n",
        "        ALL_RANKF.append(rf)\n",
        "        # windowed s (can be time-consuming; tweak window/step as needed)\n",
        "        print(f\"{text_name}: windowed s …\")\n",
        "        wins = windowed_s(tokens, window=25000, step=5000, xmin_min=2)\n",
        "        wins[\"text\"] = text_name; wins[\"pipeline\"] = pipe\n",
        "        ALL_WINS.append(wins)\n",
        "\n",
        "# Concatenate & export\n",
        "fits_df = pd.DataFrame(ALL_FITS).sort_values([\"text\",\"pipeline\"]).reset_index(drop=True)\n",
        "lr_df   = pd.concat(ALL_LR, ignore_index=True)\n",
        "heaps_df= pd.concat(ALL_HEAPS, ignore_index=True)\n",
        "rf_df   = pd.concat(ALL_RANKF, ignore_index=True)\n",
        "wins_df = pd.concat(ALL_WINS, ignore_index=True)\n",
        "\n",
        "fits_df.to_csv(TABLES/\"model_fits.csv\", index=False)\n",
        "lr_df.to_csv(TABLES/\"model_comparisons.csv\", index=False)\n",
        "heaps_df.to_csv(TABLES/\"heaps.csv\", index=False)\n",
        "rf_df.to_csv(TABLES/\"rank_freq.csv\", index=False)\n",
        "wins_df.to_csv(TABLES/\"window_s.csv\", index=False)\n",
        "\n",
        "headline = fits_df.rename(columns={\"s\":\"alpha\"})\n",
        "headline[[\"text\",\"pipeline\",\"alpha\",\"s_ci_low\",\"s_ci_high\",\"x_min\",\"ks_p\",\"tokens\",\"types\",\"n_tail\"]]\\\n",
        "        .to_csv(TABLES/\"headline_stats.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved tables:\")\n",
        "for p in sorted(TABLES.glob(\"*.csv\")):\n",
        "    print(\" -\", p.name, p.stat().st_size, \"bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvEWiNpediSL",
        "outputId": "3569e5ea-0c62-4062-e188-4898ea377d6b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== PIPELINE: conservative ===\n",
            "\n",
            "→ Tokenising FW …\n",
            "FW: tokens=218,620  types=62,255\n",
            "FW: xmin=6  alpha=1.9963  KS D=0.0143  tail_n=2,642\n",
            "FW: windowed s …\n",
            "\n",
            "→ Tokenising Ulysses …\n",
            "Ulysses: tokens=264,231  types=34,597\n",
            "Ulysses: xmin=4  alpha=1.9545  KS D=0.0059  tail_n=6,867\n",
            "Ulysses: windowed s …\n",
            "\n",
            "=== PIPELINE: canonical ===\n",
            "\n",
            "→ Tokenising FW …\n",
            "FW: tokens=219,320  types=58,083\n",
            "FW: xmin=7  alpha=2.0111  KS D=0.0167  tail_n=2,271\n",
            "FW: windowed s …\n",
            "\n",
            "→ Tokenising Ulysses …\n",
            "Ulysses: tokens=264,442  types=30,187\n",
            "Ulysses: xmin=5  alpha=1.9519  KS D=0.0077  tail_n=5,253\n",
            "Ulysses: windowed s …\n",
            "\n",
            "=== PIPELINE: generous ===\n",
            "\n",
            "→ Tokenising FW …\n",
            "FW: tokens=219,492  types=58,019\n",
            "FW: xmin=7  alpha=2.0123  KS D=0.0170  tail_n=2,278\n",
            "FW: windowed s …\n",
            "\n",
            "→ Tokenising Ulysses …\n",
            "Ulysses: tokens=264,554  types=30,158\n",
            "Ulysses: xmin=5  alpha=1.9518  KS D=0.0079  tail_n=5,256\n",
            "Ulysses: windowed s …\n",
            "\n",
            "Saved tables:\n",
            " - headline_stats.csv 741 bytes\n",
            " - headline_stats_canonical.csv 326 bytes\n",
            " - heaps.csv 604 bytes\n",
            " - model_comparisons.csv 1770 bytes\n",
            " - model_fits.csv 928 bytes\n",
            " - rank_freq.csv 6363618 bytes\n",
            " - window_s.csv 19719 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/drive/MyDrive/zipf_joyce\")\n",
        "headline = pd.read_csv(ROOT/\"results/tables/headline_stats.csv\")\n",
        "# add implied Zipf rank exponent s = 1/(alpha-1)\n",
        "headline[\"s_hat\"] = 1.0/(headline[\"s\"] - 1.0) if \"s\" in headline.columns else np.nan\n",
        "if \"alpha\" in headline.columns:\n",
        "    headline[\"s_hat\"] = 1.0/(headline[\"alpha\"] - 1.0)\n",
        "\n",
        "# show key cols if present\n",
        "cols = [c for c in [\"text\",\"pipeline\",\"alpha\",\"s\",\"s_hat\",\"x_min\",\"ks_D\",\"ks_p\",\"n_tail\",\"tokens\",\"types\",\"s_ci_low\",\"s_ci_high\",\"alpha_ci_low\",\"alpha_ci_high\"] if c in headline.columns]\n",
        "display(headline[cols].sort_values([\"text\",\"pipeline\"]).reset_index(drop=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fCpujivAxPVg",
        "outputId": "183214a3-4b48-40b4-c06d-bf87fa5a1eae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      text      pipeline     alpha     s_hat  x_min      ks_p  n_tail  tokens  \\\n",
              "0       FW     canonical  2.011055  0.989066      7  0.138577    2271  219320   \n",
              "1       FW  conservative  1.996272  1.003742      6  0.215980    2642  218620   \n",
              "2       FW      generous  2.012281  0.987868      7  0.123596    2278  219492   \n",
              "3  Ulysses     canonical  1.951869  1.050565      5  0.544320    5253  264442   \n",
              "4  Ulysses  conservative  1.954534  1.047632      4  0.670412    6867  264231   \n",
              "5  Ulysses      generous  1.951849  1.050587      5  0.490637    5256  264554   \n",
              "\n",
              "   types  s_ci_low  s_ci_high  \n",
              "0  58083  1.968700   2.056860  \n",
              "1  62255  1.959684   2.034336  \n",
              "2  58019  1.972522   2.058321  \n",
              "3  30187  1.926414   1.976456  \n",
              "4  34597  1.933773   1.975303  \n",
              "5  30158  1.929386   1.976397  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9329925c-03f2-4f9d-bb64-4ef6d36748aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>pipeline</th>\n",
              "      <th>alpha</th>\n",
              "      <th>s_hat</th>\n",
              "      <th>x_min</th>\n",
              "      <th>ks_p</th>\n",
              "      <th>n_tail</th>\n",
              "      <th>tokens</th>\n",
              "      <th>types</th>\n",
              "      <th>s_ci_low</th>\n",
              "      <th>s_ci_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FW</td>\n",
              "      <td>canonical</td>\n",
              "      <td>2.011055</td>\n",
              "      <td>0.989066</td>\n",
              "      <td>7</td>\n",
              "      <td>0.138577</td>\n",
              "      <td>2271</td>\n",
              "      <td>219320</td>\n",
              "      <td>58083</td>\n",
              "      <td>1.968700</td>\n",
              "      <td>2.056860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FW</td>\n",
              "      <td>conservative</td>\n",
              "      <td>1.996272</td>\n",
              "      <td>1.003742</td>\n",
              "      <td>6</td>\n",
              "      <td>0.215980</td>\n",
              "      <td>2642</td>\n",
              "      <td>218620</td>\n",
              "      <td>62255</td>\n",
              "      <td>1.959684</td>\n",
              "      <td>2.034336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FW</td>\n",
              "      <td>generous</td>\n",
              "      <td>2.012281</td>\n",
              "      <td>0.987868</td>\n",
              "      <td>7</td>\n",
              "      <td>0.123596</td>\n",
              "      <td>2278</td>\n",
              "      <td>219492</td>\n",
              "      <td>58019</td>\n",
              "      <td>1.972522</td>\n",
              "      <td>2.058321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ulysses</td>\n",
              "      <td>canonical</td>\n",
              "      <td>1.951869</td>\n",
              "      <td>1.050565</td>\n",
              "      <td>5</td>\n",
              "      <td>0.544320</td>\n",
              "      <td>5253</td>\n",
              "      <td>264442</td>\n",
              "      <td>30187</td>\n",
              "      <td>1.926414</td>\n",
              "      <td>1.976456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ulysses</td>\n",
              "      <td>conservative</td>\n",
              "      <td>1.954534</td>\n",
              "      <td>1.047632</td>\n",
              "      <td>4</td>\n",
              "      <td>0.670412</td>\n",
              "      <td>6867</td>\n",
              "      <td>264231</td>\n",
              "      <td>34597</td>\n",
              "      <td>1.933773</td>\n",
              "      <td>1.975303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ulysses</td>\n",
              "      <td>generous</td>\n",
              "      <td>1.951849</td>\n",
              "      <td>1.050587</td>\n",
              "      <td>5</td>\n",
              "      <td>0.490637</td>\n",
              "      <td>5256</td>\n",
              "      <td>264554</td>\n",
              "      <td>30158</td>\n",
              "      <td>1.929386</td>\n",
              "      <td>1.976397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9329925c-03f2-4f9d-bb64-4ef6d36748aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9329925c-03f2-4f9d-bb64-4ef6d36748aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9329925c-03f2-4f9d-bb64-4ef6d36748aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b42b4a9-8bd2-4aca-9d16-85e6477b8781\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b42b4a9-8bd2-4aca-9d16-85e6477b8781')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b42b4a9-8bd2-4aca-9d16-85e6477b8781 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(headline[cols]\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ulysses\",\n          \"FW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pipeline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"canonical\",\n          \"conservative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030009671338615426,\n        \"min\": 1.9518492156997251,\n        \"max\": 2.0122814104510174,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2.011055144744089,\n          1.9962723723383184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s_hat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.031215781829269738,\n        \"min\": 0.9878675926237296,\n        \"max\": 1.0505865671853059,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9890657351366456,\n          1.0037415748596266\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ks_p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2336493705940766,\n        \"min\": 0.1235955056179775,\n        \"max\": 0.6704119850187266,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.1385767790262172,\n          0.215980024968789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_tail\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1955,\n        \"min\": 2271,\n        \"max\": 6867,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2271,\n          2642\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24794,\n        \"min\": 218620,\n        \"max\": 264554,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          219320,\n          218620\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"types\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15391,\n        \"min\": 30158,\n        \"max\": 62255,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          58083,\n          62255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020881562465170575,\n        \"min\": 1.926413685090243,\n        \"max\": 1.9725223803569405,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.96870047060336,\n          1.9596839020504817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04130195990949041,\n        \"min\": 1.975302876115203,\n        \"max\": 2.058321254216772,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2.0568595531378437,\n          2.034336429002757\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Static figures**"
      ],
      "metadata": {
        "id": "kgwIzAMPds0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipf plots (log–log) per text/pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def quick_zipf_plot(df, text, pipeline):\n",
        "    sub = df[(df[\"text\"]==text)&(df[\"pipeline\"]==pipeline)]\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.scatter(sub[\"rank\"], sub[\"freq\"], s=6)\n",
        "    plt.xscale(\"log\"); plt.yscale(\"log\")\n",
        "    plt.xlabel(\"Rank (log)\"); plt.ylabel(\"Frequency (log)\")\n",
        "    plt.title(f\"Zipf — {text} · {pipeline}\")\n",
        "    out = FIGS / f\"zipf_{text}_{pipeline}.png\"\n",
        "    plt.tight_layout(); plt.savefig(out, dpi=180); plt.close()\n",
        "    return out\n",
        "\n",
        "outs = []\n",
        "for t in [\"FW\",\"Ulysses\"]:\n",
        "    for p in CONFIGS.keys():\n",
        "        outs.append(quick_zipf_plot(rf_df, t, p))\n",
        "print(\"Static figures written:\", [o.name for o in outs[:3]], \"…\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Nb91rYdu4G",
        "outputId": "e027725a-b5a2-4330-c818-4a0d0ccfa02f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Static figures written: ['zipf_FW_conservative.png', 'zipf_FW_canonical.png', 'zipf_FW_generous.png'] …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zip and (if Colab) download; also mirror to Drive**"
      ],
      "metadata": {
        "id": "pwA0GaVceQkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "ZIPPATH = RESULTS / \"zipf_results_bundle.zip\"\n",
        "with zipfile.ZipFile(ZIPPATH, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for sub in [\"tables\",\"figures\",\"dashboard\"]:\n",
        "        d = RESULTS / sub\n",
        "        if d.exists():\n",
        "            for f in d.rglob(\"*\"):\n",
        "                if f.is_file():\n",
        "                    z.write(f, f.relative_to(RESULTS))\n",
        "print(\"Zipped results →\", ZIPPATH)\n",
        "\n",
        "if IN_COLAB:\n",
        "    files.download(str(ZIPPATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pJnTIMZwfIUd",
        "outputId": "2a9e6f3c-da31-4a48-ae8d-3a791c76420b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped results → /content/drive/MyDrive/zipf_joyce/results/zipf_results_bundle.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6add345b-c419-4272-9e5f-a50d2f8340d0\", \"zipf_results_bundle.zip\", 943788)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods: Statistical Model and Inference for Zipf/Power-Law Behavior\n",
        "\n",
        "## Data and Preprocessing\n",
        "This project analyses Finnegans Wake (FW) and Ulysses prepared via a reproducible pipeline (UTF-8, NFKC, boilerplate removal, de-hyphenation at line breaks, optional header/page-number stripping). Tokenisation varies across three configurations (“conservative,” “canonical,” “generous”) to assess sensitivity. For each configuration the pipeline computes type counts \\(x_i \\in \\mathbb{N}\\) (number of occurrences per type) and operates on the multiset of counts \\(\\mathcal{X}=\\{x_1,\\dots,x_n\\}\\).\n",
        "\n",
        "**Notation.**  \n",
        "- \\(x_{\\min}\\): lower cutoff of the heavy-tail region (on counts)  \n",
        "- \\(n_{\\text{tail}}=\\#\\{x_i\\in\\mathcal{X}: x_i\\ge x_{\\min}\\}\\)  \n",
        "- \\(\\alpha\\): exponent for the discrete power law  \n",
        "- \\(s\\): Zipf exponent in the rank domain (used only for visualisation)  \n",
        "- \\(k\\): frequency value; \\(N_k\\): number of types with frequency \\(k\\)\n",
        "\n",
        "## Model: Discrete Power Law (Counts Domain)\n",
        "This project fits the discrete power law to the tail of the count distribution:\n",
        "$$\n",
        "p(x\\mid \\alpha, x_{\\min})=\\frac{x^{-\\alpha}}{\\zeta(\\alpha,x_{\\min})},\\qquad\n",
        "x\\in\\{x_{\\min},x_{\\min}{+}1,\\dots\\},\\ \\alpha>1,\n",
        "$$\n",
        "where \\(\\zeta(\\alpha,x_{\\min})\\) is the Hurwitz zeta. The tail log-likelihood for counts \\(\\{x_j\\}_{j=1}^{n_{\\text{tail}}}\\) is\n",
        "$$\n",
        "\\ell(\\alpha; x_{\\min})=-\\,n_{\\text{tail}}\\log \\zeta(\\alpha,x_{\\min})\n",
        "\\;-\\; \\alpha \\sum_{j=1}^{n_{\\text{tail}}}\\log x_j \\, .\n",
        "$$\n",
        "\n",
        "> **Why counts, not ranks?** Fitting straight lines to log–log rank plots via OLS is biased and yields unreliable uncertainty. This project estimates \\(\\alpha\\) by discrete MLE on counts and keeps rank plots for visualisation only.\n",
        "\n",
        "## Estimation\n",
        "1. **Choosing \\(x_{\\min}\\)** (tail onset).  \n",
        "   The pipeline evaluates a grid \\(x_{\\min}\\in\\mathcal{G}\\) (unique counts \\(\\ge 2\\)). For each candidate, it estimates \\(\\hat{\\alpha}(x_{\\min})\\) by MLE (bounded 1-D optimisation over \\(\\alpha>1\\)) and selects \\(\\hat{x}_{\\min}\\) that minimises the Kolmogorov–Smirnov (KS) distance between empirical and model CDFs on the tail:\n",
        "   $$\n",
        "   D(x_{\\min})=\\sup_{x\\ge x_{\\min}}\n",
        "   \\bigl|\\hat{F}(x)-F(x\\mid \\hat{\\alpha}(x_{\\min}),x_{\\min})\\bigr| \\, .\n",
        "   $$\n",
        "\n",
        "2. **Goodness-of-fit (parametric bootstrap).**  \n",
        "   With \\((\\hat{\\alpha},\\hat{x}_{\\min})\\) fixed, the pipeline generates \\(B\\) synthetic tails of size \\(n_{\\text{tail}}\\) from \\(p(x\\mid \\hat{\\alpha},\\hat{x}_{\\min})\\), re-fits \\(\\alpha\\), and recomputes KS for each; the descriptive p-value is\n",
        "   $$\n",
        "   \\hat{p}=\\frac{1+\\#\\{D^{(b)}\\ge D_{\\text{obs}}\\}}{B+1} \\, .\n",
        "   $$\n",
        "\n",
        "3. **Uncertainty in \\(\\alpha\\).**  \n",
        "   The project reports **bootstrap** 95% CIs for \\(\\alpha\\) by resampling tail counts with replacement and re-estimating \\(\\alpha\\).\n",
        "\n",
        "4. **Tail size criterion.**  \n",
        "   The analysis requires \\(n_{\\text{tail}}\\ge 50\\) (preferably \\(\\ge 100\\)) for stable inference; smaller tails are flagged and excluded from comparisons.\n",
        "\n",
        "## Model Comparison on the Same Support\n",
        "On the same tail support \\(\\{x\\ge \\hat{x}_{\\min}\\}\\), this project also fits:\n",
        "- **Lognormal (discretised)** with \\((\\mu,\\sigma)\\)  \n",
        "- **Truncated power law** \\(p(x)\\propto x^{-\\alpha}e^{-\\lambda x}\\)  \n",
        "- **Zipf–Mandelbrot** \\(p(x)\\propto (x+q)^{-s}\\) with \\(q\\ge 0\\)\n",
        "\n",
        "It uses Vuong’s likelihood-ratio test for non-nested models and reports LR, \\(z\\), and two-sided \\(p\\):\n",
        "$$\n",
        "\\mathrm{LR}=\\sum_{j=1}^{n_{\\text{tail}}}\\bigl[\\log p_A(x_j)-\\log p_B(x_j)\\bigr],\\qquad\n",
        "z=\\frac{\\mathrm{LR}}{\\hat{\\sigma}(\\Delta)\\sqrt{n_{\\text{tail}}}} \\, .\n",
        "$$\n",
        "Effect sizes and uncertainty are prioritised over binary accept/reject decisions.\n",
        "\n",
        "## Heaps’ Law (Vocabulary Growth)\n",
        "On cumulative token prefixes \\(1{:}N\\), the project measures the type–token relation and fits\n",
        "$$\n",
        "V(N)\\approx K\\,N^{\\beta}.\n",
        "$$\n",
        "It reports \\(\\hat{\\beta}\\) with a block-bootstrap CI (resampling contiguous token blocks to respect dependence). Heaps and Zipf need not agree empirically; results are therefore reported separately.\n",
        "\n",
        "## Windowed Stability of \\(\\alpha\\)\n",
        "To assess local stability, the pipeline computes \\(\\hat{\\alpha}\\) on sliding token windows (size \\(W\\), step \\(S\\)) with the same \\(x_{\\min}\\) selection per window and visualises trajectories of \\(\\hat{\\alpha}\\) alongside tail sizes \\(n_{\\text{tail}}\\).\n",
        "\n",
        "## Reporting\n",
        "For each text × tokenisation the tables include:\n",
        "- **Tail exponent** \\(\\hat{\\alpha}\\) with 95% CI\n",
        "- **Cutoff** \\(\\hat{x}_{\\min}\\), tail size \\(n_{\\text{tail}}\\), KS \\(D\\), and GoF \\(\\hat{p}\\)  \n",
        "- **Model comparisons**: LR \\(+\\) \\(z\\) \\(+\\) \\(p\\) vs lognormal, truncated, Zipf–Mandelbrot  \n",
        "- **Descriptives**: hapax share, \\(N_k\\) curve, rank–frequency (visual only)  \n",
        "- **Heaps**: \\(\\hat{\\beta}\\) with CI  \n",
        "- **Windowed** \\(\\hat{\\alpha}\\) series\n",
        "\n",
        "## Sensitivity and Reproducibility\n",
        "- **Sensitivity**: the full inference is repeated under three tokenisation regimes; optional size-matching by random subsampling controls finite-size effects.  \n",
        "- **Reproducibility**: seeds are fixed; edition and preprocessing are recorded; the \\(x_{\\min}\\) grid, optimisation bounds, and bootstrap sizes are logged. Outputs are saved as CSV to `results/tables/` and mirrored to Drive; the HTML dashboard is self-contained.\n",
        "\n",
        "## Implementation Details\n",
        "- **Optimisation**: 1-D bounded minimisation for \\(\\alpha\\in(1.0001,5]\\); 2-D bounded for Mandelbrot and truncated models. Hurwitz zeta \\(\\zeta(\\alpha,x_{\\min})\\) is evaluated with high-precision arithmetic.  \n",
        "- **KS computation**: the model CDF is evaluated on the empirical support \\(\\{x_{\\min},\\dots,x_{\\max}\\}\\); KS is the sup norm between empirical and model CDFs.  \n",
        "- **Bootstrap sizes**: default \\(B=800\\) for KS GoF and \\(\\alpha\\) CIs; \\(B\\approx300\\) for Heaps’ \\(\\beta\\) block bootstrap.  \n",
        "- **Exclusions**: fits failing the tail-size criterion or with unstable normalisers are flagged and omitted from cross-text comparisons.\n",
        "\n",
        "## Limitations\n",
        "- Tokens are dependent; bootstrap CIs reflect variability of types, not full linguistic dynamics.  \n",
        "- The discretised lognormal uses a PDF approximation with tail renormalisation (exact integrals are slower but empirically similar here).  \n",
        "- Windowed estimates fluctuate when \\(n_{\\text{tail}}\\) is small; both \\(\\hat{\\alpha}\\) and \\(n_{\\text{tail}}\\) are shown.\n",
        "\n",
        "## References\n",
        "- Clauset, Aaron, Cosma Rohilla Shalizi, and M. E. J. Newman. 2009. “Power-Law Distributions in Empirical Data.” *SIAM Review* 51 (4): 661–703.  \n",
        "- Mitzenmacher, Michael. 2004. “A Brief History of Generative Models for Power Law and Lognormal Distributions.” *Internet Mathematics* 1 (2): 226–251.  \n",
        "- Baayen, R. Harald. 2001. *Word Frequency Distributions.* Dordrecht: Kluwer.  \n",
        "- Piantadosi, Steven T. 2014. “Zipf’s Law in Natural Language: A Critical Review.” *Psychonomic Bulletin & Review* 21 (5): 1112–1130.\n"
      ],
      "metadata": {
        "id": "dcb_N70_i_A1"
      }
    }
  ]
}